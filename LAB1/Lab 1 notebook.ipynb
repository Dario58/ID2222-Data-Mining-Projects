{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L13SuBkX81Ui"
      },
      "source": [
        "# LAB.1\n",
        "## Homework 1: Finding Similar Items: Textually Similar Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1RXS2HIoa2H",
        "outputId": "df11d07f-38c8-418b-8206-e0d95d225ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/DM_Labs/dataset')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The aim of the project was to find textually similar documents based on Jaccard similarity using the shingling, minhashing, and locality-sensitive hashing (LSH) techniques.\n",
        "We have taken the MeDAL dataset (Medical Dataset for Abbreviation Disambiguation for Natural Language Understanding), that is a large medical text dataset curated for abbreviation disambiguation. "
      ],
      "metadata": {
        "id": "d5WX2ii_Ox2-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bAcLW8dp8Sbc"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/DM_Labs/dataset/data.csv', sep='\\t', on_bad_lines='skip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ2oCdsHJVw5"
      },
      "source": [
        "Visualizing loaded rows out of 1M rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VFG0NyNBJenD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "f502979b-4a48-4495-af43-136f90fb57d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0                                               TEXT  \\\n",
              "0                0  alphabisabolol has a primary antipeptic action...   \n",
              "1                1  a report is given on the recent discovery of o...   \n",
              "2                2  the virostatic compound nndiethyloxotetradecyl...   \n",
              "3                3  rmi rmi and rmi are newly synthetized nrdibenz...   \n",
              "4                4  a doubleblind study with intraindividual compa...   \n",
              "...            ...                                                ...   \n",
              "999995      999995  the human gene for producing alcohol dehydroge...   \n",
              "999996      999996  measurement of CS in saliva has excited intere...   \n",
              "999997      999997  a timeresolved fluoroimmunoassay trfia for unc...   \n",
              "999998      999998  porphyria cutanea tarda pct results from a met...   \n",
              "999999      999999  recent advances in methodology allow the mass ...   \n",
              "\n",
              "                          LOCATION  \\\n",
              "0                               56   \n",
              "1             24|49|68|113|137|172   \n",
              "2                               55   \n",
              "3                25|82|127|182|222   \n",
              "4       22|26|28|77|90|144|158|203   \n",
              "...                            ...   \n",
              "999995                       24|59   \n",
              "999996        2|27|64|74|76|83|118   \n",
              "999997             14|15|37|60|173   \n",
              "999998                   59|64|205   \n",
              "999999                          62   \n",
              "\n",
              "                                                    LABEL  \n",
              "0                                               substrate  \n",
              "1       carcinosarcoma|recovery|reference|recovery|aft...  \n",
              "2                                               substrate  \n",
              "3       compounds|compounds|inhibitory|lethal doses|ca...  \n",
              "4       oxazepam|placebo|oral administration|pentagast...  \n",
              "...                                                   ...  \n",
              "999995                              liver biopsy|complete  \n",
              "999996  steroids|active|serum|sensitive|specific|assay...  \n",
              "999997  serum|albumin|antiserum|after|vitro fertilization  \n",
              "999998                           groups|study|degradation  \n",
              "999999                                    electrophoresis  \n",
              "\n",
              "[1000000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24f2a28c-56f8-4228-91ab-4f8669107e94\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>LABEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>alphabisabolol has a primary antipeptic action...</td>\n",
              "      <td>56</td>\n",
              "      <td>substrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>a report is given on the recent discovery of o...</td>\n",
              "      <td>24|49|68|113|137|172</td>\n",
              "      <td>carcinosarcoma|recovery|reference|recovery|aft...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>the virostatic compound nndiethyloxotetradecyl...</td>\n",
              "      <td>55</td>\n",
              "      <td>substrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>rmi rmi and rmi are newly synthetized nrdibenz...</td>\n",
              "      <td>25|82|127|182|222</td>\n",
              "      <td>compounds|compounds|inhibitory|lethal doses|ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>a doubleblind study with intraindividual compa...</td>\n",
              "      <td>22|26|28|77|90|144|158|203</td>\n",
              "      <td>oxazepam|placebo|oral administration|pentagast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999995</th>\n",
              "      <td>999995</td>\n",
              "      <td>the human gene for producing alcohol dehydroge...</td>\n",
              "      <td>24|59</td>\n",
              "      <td>liver biopsy|complete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999996</th>\n",
              "      <td>999996</td>\n",
              "      <td>measurement of CS in saliva has excited intere...</td>\n",
              "      <td>2|27|64|74|76|83|118</td>\n",
              "      <td>steroids|active|serum|sensitive|specific|assay...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999997</th>\n",
              "      <td>999997</td>\n",
              "      <td>a timeresolved fluoroimmunoassay trfia for unc...</td>\n",
              "      <td>14|15|37|60|173</td>\n",
              "      <td>serum|albumin|antiserum|after|vitro fertilization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999998</th>\n",
              "      <td>999998</td>\n",
              "      <td>porphyria cutanea tarda pct results from a met...</td>\n",
              "      <td>59|64|205</td>\n",
              "      <td>groups|study|degradation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999999</th>\n",
              "      <td>999999</td>\n",
              "      <td>recent advances in methodology allow the mass ...</td>\n",
              "      <td>62</td>\n",
              "      <td>electrophoresis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24f2a28c-56f8-4228-91ab-4f8669107e94')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24f2a28c-56f8-4228-91ab-4f8669107e94 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24f2a28c-56f8-4228-91ab-4f8669107e94');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVWL-n-l9aeu"
      },
      "source": [
        "We take only a slice of the dataset and drop all the columns that are different from **TEXT**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f_lgR6898mt4"
      },
      "outputs": [],
      "source": [
        "small_dataset = dataset[:1000]\n",
        "small_dataset = small_dataset['TEXT']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "H2MkU-V19zdZ",
        "outputId": "51d936ad-fff9-4834-c4eb-5dff4da05c03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'alphabisabolol has a primary antipeptic action depending on dosage which is not caused by an alteration of the phvalue the proteolytic activity of pepsin is reduced by percent through addition of bisabolol in the ratio of the antipeptic action of bisabolol only occurs in case of direct contact in case of a previous contact with the ATP the inhibiting effect is lost'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "small_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWcnGU3E97Nt"
      },
      "source": [
        "# Shingling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33xN1MdG-Cbr"
      },
      "source": [
        "Let's define a function that constructs k–shingles of a given length (k=5) from a given document, computes a hash value for each unique shingle and represents the document in the form of an ordered set of its hashed k-shingles.\n",
        "Defining a shingling function that uses **list comprehension**, defining a loop while iterating the list to make it faster. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rdiQ4Y0y-Ktk"
      },
      "outputs": [],
      "source": [
        "def shingles(text, size):\n",
        "    chars = list(text) # Splitting the text\n",
        "    return [''.join(chars[i:i+size]) for i in range(len(chars) - size + 1)]\n",
        "# Joining with an empty char from the i-th char to the 'i-th + size-1' char, 'len(chars) - size + 1' times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sugQaeNG-PSt"
      },
      "source": [
        "**k = 5** for small documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJkQjvnm-P4m",
        "outputId": "b3f27831-3337-4dfc-a056-d3c5f4fd0a28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alpha',\n",
              " 'lphab',\n",
              " 'phabi',\n",
              " 'habis',\n",
              " 'abisa',\n",
              " 'bisab',\n",
              " 'isabo',\n",
              " 'sabol',\n",
              " 'abolo',\n",
              " 'bolol']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "k = 5\n",
        "five_shingles = shingles(small_dataset[0], k)\n",
        "five_shingles[:10] # Just to show the first 10 5-shingles of the first document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf8JDD9s-QT4"
      },
      "source": [
        "**crc32** will be used to hash the shingles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OWvC4WnQ-RLU"
      },
      "outputs": [],
      "source": [
        "from binascii import crc32\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3bMb3JVe-kIw"
      },
      "outputs": [],
      "source": [
        "def shinglify(dataset, k):\n",
        "    \n",
        "    t0 = time.time()\n",
        "    docs_as_hashed_shingles = {}\n",
        "    \n",
        "    # For each document\n",
        "    for i in range(len(dataset)):\n",
        "        hashed_shingles = set()\n",
        "        text = dataset[i]\n",
        "        \n",
        "        # For each shingle\n",
        "        for shingle in set(shingles(text, k)): # Directly converts to a shingle set to avoid repetitions\n",
        "            crc_hash = crc32(shingle.encode('utf-8')) & 0xffffffff\n",
        "            hashed_shingles.add(crc_hash)\n",
        "        \n",
        "        docs_as_hashed_shingles[i] = hashed_shingles\n",
        "    \n",
        "    t1 = time.time()\n",
        "    return docs_as_hashed_shingles, t0, t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkTzFy81-nCS",
        "outputId": "1791536d-dbaa-4acb-b226-ad8d43f31ca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-Shingling 1000 docs took: 0.75 seconds\n"
          ]
        }
      ],
      "source": [
        "shingled_dataset, t0, t1 = shinglify(small_dataset, k) # Returns times as well\n",
        "print(str(k) + '-Shingling ' + str(len(small_dataset)) + ' docs took: %.2f seconds' %(t1 - t0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7027ca6CX1A"
      },
      "source": [
        "# Compare Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define a method which computes the **Jaccard similarity** of two sets of integers: two sets of hashed  shingles. "
      ],
      "metadata": {
        "id": "d4b-JcTaTC2i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "3pmdkL54KWOV"
      },
      "outputs": [],
      "source": [
        "def jaccard_2docs(doc1: set, doc2: set):\n",
        "  return len(doc1 & doc2)/len(doc1 | doc2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "-HDU6R0ZM45l"
      },
      "outputs": [],
      "source": [
        "def similarity_matrix(shingled_dataset):\n",
        "  \n",
        "  t0 = time.time()\n",
        "  sim_matrix = np.zeros((len(small_dataset),len(small_dataset)))\n",
        "\n",
        "  for row in range(len(small_dataset)):\n",
        "    for col in range(row, len(small_dataset)):\n",
        "      if(row == col): # Skipping the similarity for the same document as it would be 1\n",
        "        continue\n",
        "      sim_matrix[row][col] = jaccard_2docs(shingled_dataset[row], shingled_dataset[col])\n",
        "  \n",
        "  t1 = time.time()\n",
        "  return sim_matrix, t0, t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hygQ6nauVMop",
        "outputId": "62223ed2-ae48-4477-ee5b-40e6862b01a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "double-loop Similarity Matrix computation for 1000 docs took: 50.52 seconds\n"
          ]
        }
      ],
      "source": [
        "sim_matrix, t0, t1 = similarity_matrix(shingled_dataset)\n",
        "shingling_sim_time = t1 - t0\n",
        "print('double-loop Similarity Matrix computation for ' + str(len(small_dataset)) + ' docs took: %.2f seconds' %shingling_sim_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saved the time for the first technique."
      ],
      "metadata": {
        "id": "D7H_URSwkQ0l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fON0lI7sWPqc",
        "outputId": "30c86b35-6e5d-485c-f304-c9e5935bb7e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.05121639, 0.06199461, 0.05589226, 0.04317656,\n",
              "       0.07427938, 0.05474453, 0.05051546, 0.05222734, 0.05682782])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "sim_matrix[0][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print the maximum of the similarity matrix and finding which are the documents with the maximum value."
      ],
      "metadata": {
        "id": "7N34FnOyThKD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eENL_W0W9ie",
        "outputId": "c63dd0bd-4196-485c-8495-5d48a390e4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4558180227471566\n",
            "(173, 175)\n"
          ]
        }
      ],
      "source": [
        "print(np.max(sim_matrix))\n",
        "print(np.unravel_index(np.argmax(sim_matrix, axis=None), sim_matrix.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the following texts have some parts in common."
      ],
      "metadata": {
        "id": "zTr6l2IGT1OK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "6glc0LJGYKS9",
        "outputId": "98f6e17d-e055-4cc6-d17b-9f1dd35d040f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'reduced coenzyme qcytochrome c reductase from bovine heart mitochondria complex iii was incorporated into phospholipid LDV by the cholate dialysis procedure soybean phospholipids or mixtures of purified phosphatidylcholine phosphatidylethanolamine and cardiolipin could be used oxidation of reduced coenzyme q by the reconstituted vesicles with cytochrome c as oxidant showed the following energycoupling phenomena protons were translocated outward with a coupling ratio he of measurements with mitochondria under similar conditions showed an he ratio of proton translocation was not seen in the presence of uncoupling agents and was in addition to the net acidification of the medium from the overall oxidation reaction potassium ions were taken up by the reconstituted vesicles in the presence of valinomycin in a reaction coupled to electron transfer the coupling ratio for k uptake ke was in the vesicles and approximately in mitochondria the rate of oxidation of reduced coenzyme q by the reconstituted LDV was stimulated up to fold by uncouplers or by valinomycin plus nigericin and k ions addition of valinomycin CT in a k medium caused a transient stimulation of electron transfer the results indicate that SE coupling can be observed with isolated reduced coenzyme qcytochrome c reductase if the enzyme complex is properly incorporated into a phospholipid vesicle'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "small_dataset[173]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "68yoymvYYP-x",
        "outputId": "0596c4cc-e39f-43fc-a1be-2e23962a2aa8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nadhcoenzyme q reductase from bovine heart mitochondria complex i was incorporated into phospholipid LDV by the cholate dialysis procedure mixtures of purified phosphatidylcholine and phosphatidylethanolamine were required oxidation of nadh by coenzyme q catalyzed by the reconstituted vesicles was coupled to proton translocation directed inward with an he ratio greater than similar experiments measuring proton translocation in submitochondrial particles gave an he ratio of the proton translocation in both systems was not seen in the presence of uncoupling agents and was in addition to the net proton uptake from the reduction of coenzyme q by nadh electron transfer in the reconstituted LDV also caused the uptake of the permeant anion tetraphenylboron the rate of electron transfer by the reconstituted vesicles was stimulated about fold by uncouplers or by valinomycin plus nigericin and k ions the results indicate that energy coupling can be observed with isolated nadhcoenzyme q reductase if the enzyme complex is properly incorporated into a phospholipid vesicle'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "small_dataset[175]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Min Hashing"
      ],
      "metadata": {
        "id": "_66-4LFDDkeM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define a function which builds a minHash signature (in the form of a vector or a set) of a given length n from a given set of integers (a set of hashed shingles)."
      ],
      "metadata": {
        "id": "OF9OgBq5T_2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, we take *numHashes* independent hash functions."
      ],
      "metadata": {
        "id": "0VMrXTtVKGQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# number of random hash functions\n",
        "num_hashes = 100"
      ],
      "metadata": {
        "id": "M0TS0qy5MICa"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, we find the *maxShingleID*, that will be used lately for the hash function."
      ],
      "metadata": {
        "id": "CirAVDXBUmaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "\n",
        "maxShingleID = 0\n",
        "\n",
        "for doc_id in shingled_dataset:\n",
        "  \n",
        "  shingle_id_set = shingled_dataset[doc_id]\n",
        "  signature = []\n",
        "  \n",
        "  for i in range(0, num_hashes):\n",
        "      \n",
        "    for shingle_id in shingle_id_set:\n",
        "      \n",
        "      if(maxShingleID < shingle_id):\n",
        "        maxShingleID = shingle_id\n",
        "\n",
        "t1 = time.time()\n",
        "max_shingle_time = t1 - t0"
      ],
      "metadata": {
        "id": "YEGiJO5hGycU"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(maxShingleID)\n",
        "\n",
        "# We need the next largest prime number after 'maxShingleID'.\n",
        "# http://compoasso.free.fr/primelistweb/page/prime/liste_online_en.php\n",
        "nextPrime = 4294895617"
      ],
      "metadata": {
        "id": "4qrpDvs1dWp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39bd2563-bcb7-4b54-c78c-b2bfc15a807f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4294895493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "def random_coeffs(k):\n",
        "  # k random vaues\n",
        "  rand_list = []\n",
        "  \n",
        "  for i in range(k):\n",
        "    # random shingle ID\n",
        "    rand_idx = random.randint(0, maxShingleID) \n",
        "  \n",
        "    # uniqueness check\n",
        "    while rand_idx in rand_list:\n",
        "      rand_idx = random.randint(0, maxShingleID) \n",
        "    \n",
        "    rand_list.append(rand_idx)\n",
        "    \n",
        "  return rand_list\n"
      ],
      "metadata": {
        "id": "VWh7YTNZcuYH"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each hash function, generate a different coefficient **a** and **b**.   "
      ],
      "metadata": {
        "id": "lNBjI5jVxe6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coeff_A = random_coeffs(num_hashes)\n",
        "coeff_B = random_coeffs(num_hashes)"
      ],
      "metadata": {
        "id": "Sez6EFpztEvt"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking that they're not representing the same line (like 3x+12 and x+4)."
      ],
      "metadata": {
        "id": "9nas5jFyzIyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b in zip(coeff_A, coeff_B):\n",
        "  assert a not in coeff_B\n",
        "  assert b not in coeff_A\n",
        "  \n",
        "  for x, y in zip(coeff_A, coeff_B):\n",
        "    if(a != x and b != y):\n",
        "      assert a/b != x/y"
      ],
      "metadata": {
        "id": "r2HBMgT_yCqE"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each of the shingles of a document, calculate its hash using $i_{th}$ hash function."
      ],
      "metadata": {
        "id": "i2VeuOyd2jTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "# docs as signatures\n",
        "signatures = []\n",
        "\n",
        "for doc_id in shingled_dataset:\n",
        "  \n",
        "  shingle_id_set = shingled_dataset[doc_id]\n",
        "\n",
        "  signature = [] # result signature\n",
        "  \n",
        "  for i in range(num_hashes):\n",
        "    min_hash = nextPrime + 1 # initialize min_hash to be greater than the nextPrime\n",
        "    \n",
        "    for shingle_id in shingle_id_set:\n",
        "      \n",
        "      hash_code = (coeff_A[i] * shingle_id + coeff_B[i]) % nextPrime # (ax + b) % c\n",
        "  \n",
        "      if hash_code < min_hash:\n",
        "        min_hash = hash_code\n",
        "\n",
        "    signature.append(min_hash) # keep the min_hash\n",
        "  \n",
        "  signatures.append(signature) # keep the entire signature of document doc_id\n",
        "\n",
        "t1 = time.time()\n",
        "min_hashing_time = t1 - t0\n",
        "min_hashing_time"
      ],
      "metadata": {
        "id": "-R6oIl5TfNXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e96f811-7655-4aba-b69d-033b0eaf190b"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32.12442111968994"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_docs = len(shingled_dataset) # 1000"
      ],
      "metadata": {
        "id": "7eQ2IK3UlSpa"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time to compare the signatures (task 4):"
      ],
      "metadata": {
        "id": "cB7kE8QP38cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_signatures():\n",
        "  t0 = time.time()\n",
        "  matrix = np.zeros((len(shingled_dataset), len(shingled_dataset)))\n",
        "\n",
        "  for i in range(num_docs):\n",
        "\n",
        "    doc1_signature = signatures[i]\n",
        "      \n",
        "    # For each of the other test documents...\n",
        "    for j in range(i, num_docs):\n",
        "      \n",
        "      if(i == j):\n",
        "        continue  \n",
        "      doc2_signature = signatures[j]\n",
        "\n",
        "      count = 0\n",
        "      for k in range(num_hashes):\n",
        "        agree = 0\n",
        "        if(doc1_signature[k] == doc2_signature[k]):\n",
        "          agree = 1\n",
        "        count = count + agree  # on how many do they agree?\n",
        "      \n",
        "      matrix[i][j] = float(count) / float(num_hashes) # assigning similarity\n",
        "  t1 = time.time()\n",
        "  return matrix, (t1 - t0)"
      ],
      "metadata": {
        "id": "8ogAofOnjFKD"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The percentuage matrix will have on the rows and on the columns all the documents. "
      ],
      "metadata": {
        "id": "Yxum3VYhVTE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minHash_sim_matrix, compare_time = compare_signatures()"
      ],
      "metadata": {
        "id": "xUdWazLk1RsK"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minHash_tot_time = max_shingle_time + min_hashing_time + compare_time\n",
        "minHash_tot_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks9plWjKGjwy",
        "outputId": "72538d02-b7e6-4d17-8bed-1c2b427ed495"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46.102508544921875"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.3"
      ],
      "metadata": {
        "id": "GUjzjDjeAr-2"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_docs):  \n",
        "  for j in range(i, num_docs):\n",
        "    \n",
        "    if(i == j):\n",
        "      continue\n",
        "\n",
        "    if minHash_sim_matrix[i][j] > threshold:\n",
        "      print (minHash_sim_matrix[i][j])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfWK5wz2pCXN",
        "outputId": "db113506-363a-4baa-b041-a251daf8b375"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n",
            "0.32\n",
            "0.44\n",
            "0.35\n",
            "0.31\n",
            "0.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The documents number 408 and 410 have the highest percentuge of same hash values."
      ],
      "metadata": {
        "id": "JgTrLYTYXG9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.max(minHash_sim_matrix))\n",
        "print(np.unravel_index(np.argmax(minHash_sim_matrix, axis=None), minHash_sim_matrix.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVChNlqEW3Ob",
        "outputId": "303c1a5d-732d-42b4-d80c-7c16b9cbfe53"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.44\n",
            "(408, 410)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check values of before:"
      ],
      "metadata": {
        "id": "yEgJ6ViKF0cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(minHash_sim_matrix[173, 175]) # still high similarity on these two"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdmaQJcBEhS5",
        "outputId": "4119d638-6965-466b-88d7-73fc9c92f462"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_dataset[408]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "gIkQ0H4jF5td",
        "outputId": "65776492-71ff-43e5-d539-18dad9ca0fb7"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the nadpspecific glu dehydrogenase of neurospora crassa was digested with trypsin and peptides accounting for out of the residues of the polypeptide chain were isolated and substantially sequenced additional experimental detail has been deposited as supplementary publication sup pages with the british library lending division boston spa wetherby w yorkshire ls bq uk from whom copies may be obtained under the terms given in biochem j'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_dataset[410]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "jimUeWNkGA01",
        "outputId": "e1dcc135-5fed-44a2-f3aa-d544fcadb302"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'peptic and chymotryptic peptides were isolated form the nadpspecific glutamate dehydrogenase of neurospora crassa and substantially sequenced out of residues in the polypeptide chain were recovered in the peptic and in the chymotryptic peptides together with the tryptic peptides wootton j c taylor j g jackson a a chambers g k fincham j r s biochem j these establish the CR CS of the chain including the acid and NH assignments except for seven places where overlaps are inadequate these remaining alignments are deduced from information on the cnbr fragments obtained in another laboratory blumenthal k m moon k smith e l j biol chem further information has been deposited as supplementary publication sup pages with the british library lending division boston spa wetherby w yorkshire ls bq uk from whom copies may be obtained under the terms given in biochem j'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same words: boston, biochem, j, ls, bq, uk, dehydrogenase, neurospora, polypeptide, etc..."
      ],
      "metadata": {
        "id": "t90w1Wm7GKtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# LSH\n"
      ],
      "metadata": {
        "id": "lEGiCW2_Ze3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A class LSH that implements the LSH technique: given a collection of minhash signatures (integer vectors) and a similarity threshold $t$, the LSH class (using **banding** and hashing) finds candidate pairs of signatures agreeing on at least a fraction $t$ of their components."
      ],
      "metadata": {
        "id": "Wqm9P_m3O14T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\{_{b \\space r = n}^{(1/b)^{1/r} \\sim s}$ remember from the slides."
      ],
      "metadata": {
        "id": "wbhlsA93OHGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bands = 20 # between 1 and the number of hashes 100\n",
        "rows_per_band = num_hashes / bands\n",
        "lsh_threshold = 1/bands ** (1/float(rows_per_band))\n",
        "lsh_threshold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajuX2ANJPz_R",
        "outputId": "58901a9f-6303-430f-8661-f9a120dd1804"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5492802716530589"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a function that given a signature and number of bands, returns a band_hash_list containing the cycled mod_bands buuckets of the hashes of the signature. "
      ],
      "metadata": {
        "id": "SOV-KIDmTngS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def band_hash(bands, minHash_signature):\n",
        "  band_hash_list = []\n",
        "  band_hash = 0\n",
        "  for i in range(len(minHash_signature)): # for every hash in the signature\n",
        "\n",
        "        if i % bands == 0: # number of bands modular cycle (#bands different classes)\n",
        "\n",
        "            if i > 0:\n",
        "              band_hash_list.append(band_hash)\n",
        "            band_hash = 0\n",
        "\n",
        "        band_hash = hash(minHash_signature[i]) # hashing i-th value of the signature\n",
        "  \n",
        "  return band_hash_list\n",
        "  '''"
      ],
      "metadata": {
        "id": "nmW-Tc5gQlIn"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the LSH function."
      ],
      "metadata": {
        "id": "EWFtPiYIY4dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import time"
      ],
      "metadata": {
        "id": "6R1bJlWhnTWO"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def LSH(signatures, threshold, bands, num_hashes):\n",
        "  t0 = time.time()\n",
        "\n",
        "  final_result = {} # dict: (pair of similar documents) -> similarity (> threshold)\n",
        "\n",
        "  lsh_signatures = {}\n",
        "  band_hashes = {}\n",
        "  doc_id = 0\n",
        "\n",
        "  for signature in signatures:\n",
        "\n",
        "    lsh_signatures[doc_id] = signature\n",
        "    minhash_sig = signature\n",
        "    new_hashes = band_hash(bands, minhash_sig)\n",
        "\n",
        "    # Time to construct the dictionary that links signatures and buckets\n",
        "\n",
        "    for i in range(len(new_hashes)): # for every element of the new hashes\n",
        "      \n",
        "      if i not in band_hashes: # if not already added\n",
        "        band_hashes[i] = {} # create instance in the dictionary\n",
        "\n",
        "      if new_hashes[i] not in band_hashes[i]:\n",
        "        band_hashes[i][new_hashes[i]] = [] # insert the first element\n",
        "        band_hashes[i][new_hashes[i]].append(doc_id)\n",
        "      else: \n",
        "        band_hashes[i][new_hashes[i]].append(doc_id)\n",
        "    \n",
        "    doc_id = doc_id + 1\n",
        "  \n",
        "  found_similarities = set()\n",
        "  # Compare each bucket signatures\n",
        "  for h in band_hashes:\n",
        "    for bucket in band_hashes[h]:\n",
        "    \n",
        "      if len(band_hashes[h][bucket]) > 1: # if at least two elements...\n",
        "        for two_docs in itertools.combinations(band_hashes[h][bucket], r=2):\n",
        "          if two_docs not in found_similarities:\n",
        "            found_similarities.add(two_docs)\n",
        "\n",
        "            sim = jaccard_2docs(set(lsh_signatures[two_docs[0]]), set(lsh_signatures[two_docs[1]]))\n",
        "            if(float(sim) > lsh_threshold):\n",
        "              print(sim)\n",
        "              final_result[two_docs] = sim\n",
        "\n",
        "  t1 = time.time()\n",
        "  return final_result, (t1 - t0)\n",
        "'''"
      ],
      "metadata": {
        "id": "jSVj7y-kZinB"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Couldn't get the last part to work, some fixes are needed."
      ],
      "metadata": {
        "id": "R1qnp5ilTqdV"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}